{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zillow\n",
    "\n",
    "For the following, iterate through the steps you would take to create functions: Write the code to do the following in a jupyter notebook, test it, convert to functions, then create the file to house those functions.\n",
    "\n",
    "You will have a `zillow.ipynb` file and a helper file for each section in the pipeline.\n",
    "\n",
    "**Summarize Zillow Database**\n",
    "\n",
    "- airconditioningtype: 13 unique values\n",
    "    - primary key: airconditioningtypeid\n",
    "\n",
    "\n",
    "- architecturalstyletype: 27 unique values\n",
    "    - primary key: architecturalstyletypeid\n",
    "    \n",
    "    \n",
    "- buildingclasstype: 5 unique values\n",
    "    - primary key: buildingclasstypeid\n",
    "    \n",
    "    \n",
    "- heatingorsystemtype: 25 unique values\n",
    "    - primary key: heatingorsystemtypeid\n",
    "    \n",
    "    \n",
    "- predictions_2016: all the transactions in 2016 \n",
    "    - No need to be joined\n",
    "    \n",
    "    \n",
    "- predictions_2017: 77614 records in total\n",
    "    - primary key: parcelid\n",
    "    - 77613 records in 2017\n",
    "    - 1 record in 2018\n",
    "    - unique id: 77614\n",
    "    - **unique parcelid: 77414**\n",
    "    \n",
    "    \n",
    "- properties_2016: No need to be joined\n",
    "\n",
    "\n",
    "- properties_2017: main table\n",
    "    - primary key: parcelid\n",
    "    \n",
    "    \n",
    "- propertylandusetype\n",
    "    - primary key: propertylandusetypeid\n",
    "    \n",
    "    \n",
    "- storytype: 35 unique values\n",
    "    - primary key: storytypeid\n",
    "    \n",
    "\n",
    "- typeconstructiontype: 18 unqiue values\n",
    "    - primary key: typeconstructiontypeid\n",
    "    \n",
    "    \n",
    "- unique_properties: 2,985,217 rows\n",
    "    - primary key: parcelid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## acquire & summarize\n",
    "\n",
    "### 1. Acquire data from mySQL using the python module to connect and query. You will want to end with **a single dataframe**. Make sure to include: the logerror, all fields related to the properties that are available. You will end up **using all the tables in the database**.\n",
    "- Be sure to do **the correct join (inner, outer, etc.)**. We do not want to eliminate properties purely because they may have a null value for airconditioningtypeid.\n",
    "- Only include properties with a **transaction in 2017**, and include **only the last transaction for each properity** (so no duplicate property ID's), along with zestimate error and date of transaction.\n",
    "- Only include properties that include a latitude and longitude value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import env, acquire, summarize, prepare, wrangle_zillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire properties with a transaction in 2017 order first by parcelid then transactiondate\n",
    "\n",
    "query = \"\"\"\n",
    "        select *\n",
    "        from properties_2017\n",
    "        join predictions_2017 using(parcelid)\n",
    "        left join airconditioningtype using(airconditioningtypeid)\n",
    "        left join architecturalstyletype using(architecturalstyletypeid)\n",
    "        left join buildingclasstype using(buildingclasstypeid)\n",
    "        left join heatingorsystemtype using(heatingorsystemtypeid)\n",
    "        left join propertylandusetype using(propertylandusetypeid)\n",
    "        left join storytype using(storytypeid)\n",
    "        left join typeconstructiontype using(typeconstructiontypeid)\n",
    "        where transactiondate between '2017-01-01' and '2017-12-31'\n",
    "        order by parcelid, transactiondate\n",
    "        \"\"\"\n",
    "\n",
    "df = acquire.get_zillow_data(query, '1')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address duplicates: show all duplicates\n",
    "\n",
    "mask = df.duplicated(subset='parcelid', keep=False)\n",
    "df_duplicated = df[mask]\n",
    "df_duplicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only kee the last transaction (the most recent) for each properity. \n",
    "\n",
    "df.drop_duplicates(subset=['parcelid'], keep='last', inplace=True, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see whether the property with most transatction date is kept.\n",
    "\n",
    "df[(df.parcelid == 10722858) | (df.parcelid == 10732347)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there exsits duplicate property ID\n",
    "\n",
    "df.duplicated(subset='parcelid').any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**: Properties with transaction in 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarize your data (summary stats, info, dtypes, shape, distributions, value_counts, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = prepare.drop_zillow_duplicates(df)\n",
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summary stats\n",
    "\n",
    "zillow.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Info\n",
    "\n",
    "zillow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display object columns and the counts of unique values\n",
    "\n",
    "zillow_obj_sum = summarize.sum_obj_cols(zillow)\n",
    "zillow_obj_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count unique values in each attributes\n",
    "\n",
    "summarize.obj_value_counts(zillow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_num = summarize.num_df(zillow)\n",
    "zillow_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_obj = summarize.obj_df(zillow)\n",
    "zillow_obj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a function that takes in a dataframe of observations and attributes and returns a dataframe where each row is an atttribute name, the first column is the number of rows with missing values for that attribute, and the second column is percent of total rows that have missing values for that attribute. Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of rows with missing values \n",
    "\n",
    "attributes_missing_values = pd.DataFrame(zillow.isna().sum(axis=0), columns=['num_row_missing'])\n",
    "attributes_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add a column to compute the percent of total rows that have missing values\n",
    "\n",
    "total_rows = zillow.shape[0]\n",
    "\n",
    "attributes_missing_values['pct_rows_missing'] = attributes_missing_values.num_row_missing/total_rows\n",
    "attributes_missing_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "\n",
    "attributes_missing_values = summarize.sum_missing_values_attributes(zillow)\n",
    "attributes_missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a function that takes in a dataframe and returns a dataframe with 3 columns: the number of columns missing, percent of columns missing, and number of rows with n columns missing. Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows based on how many missing values in that row. \n",
    "\n",
    "x = zillow.isnull().sum(axis=1).value_counts().sort_index()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the dictionary from list of lists\n",
    "\n",
    "cols_missing_values = pd.DataFrame([x.index.tolist(), x.values.tolist()], \n",
    "                                   index = ['num_cols_missing', 'num_rows'])\n",
    "cols_missing_values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the dictionary from dict\n",
    "\n",
    "d = {'num_cols_missing': x.index.tolist(), 'num_rows': x.values.tolist()}\n",
    "\n",
    "cols_missing_values = pd.DataFrame(d)\n",
    "cols_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percent of columns missing\n",
    "\n",
    "n = zillow.shape[0] # Compuate the total number of rows\n",
    "cols_missing_values['pct_cols_missing'] = (cols_missing_values.num_rows/n)*100\n",
    "cols_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the \n",
    "\n",
    "x = cols_missing_values.num_cols_missing\n",
    "y = cols_missing_values.num_rows\n",
    "\n",
    "plt.rc('figure', figsize=(13,7))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt. bar(x, y)\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.barplot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "\n",
    "cols_missing_values = summarize.sum_missing_values_cols(zillow)\n",
    "cols_missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare\n",
    "### 1. Remove any properties that are likely to be something other than single unit properties. (e.g. no duplexes, no land/lot, ...). \n",
    "- There are multiple ways to estimate that a property is a single unit, and there is not a single \"right\" answer. But for this exercise, do not purely filter by unitcnt as we did previously. \n",
    "- Add some new logic that will reduce the number of properties that are falsely removed. \n",
    "- You might want to use # bedrooms, square feet, unit type or the like to then identify those with unitcnt not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.propertylandusetypeid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zillow.propertylandusedesc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the propertylandusetypeids previously used in regression project\n",
    "# It is better done in the SQL\n",
    "\n",
    "single_unit = [260, 261, 262, 279]\n",
    "\n",
    "zillow = zillow[zillow.propertylandusetypeid.isin(single_unit)]\n",
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zillow.propertylandusetypeid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a function that will drop rows or columns based on the percent of values that are missing: handle_missing_values(df, prop_required_column, prop_required_row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function based on the curriculum. \n",
    "\n",
    "def handle_missing_values(df, prop_required_column, prop_required_row):\n",
    "    \"\"\"\n",
    "    Drop rows and columsn based on the perent of values that are missing.\n",
    "    Parameters: \n",
    "    1. df\n",
    "    2. the proportion, for each column, of rows with non-missing values requied to keep the column\n",
    "    3. the proportion, for each row, of columns with non-missing values required to keep the row\n",
    "    \"\"\"\n",
    "    threshold = int(round(prop_required_column*len(df.index),0))\n",
    "    df.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "    threshold = int(round(prop_required_row*len(df.columns),0))\n",
    "    df.dropna(axis=0, thresh=threshold, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function: the columns has no more than 40% missing and the rows has no more than 25% missing\n",
    "\n",
    "zillow_dropna = handle_missing_values(zillow, 0.6, 0.75)\n",
    "zillow_dropna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the inplace = True, the zillow dataset have been modified.  \n",
    "\n",
    "zillow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decide how to handle the remaining missing values\n",
    "- Drop row/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row/column with missing values\n",
    "\n",
    "mask = zillow.isna().sum(axis=1) == 0\n",
    "zillow_handle_na = zillow[mask]\n",
    "zillow_handle_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if there is any missing values in the dataframe\n",
    "\n",
    "zillow_handle_na.isna().sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Test the functions in .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77613, 69)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "        select *\n",
    "        from properties_2017\n",
    "        join predictions_2017 using(parcelid)\n",
    "        left join airconditioningtype using(airconditioningtypeid)\n",
    "        left join architecturalstyletype using(architecturalstyletypeid)\n",
    "        left join buildingclasstype using(buildingclasstypeid)\n",
    "        left join heatingorsystemtype using(heatingorsystemtypeid)\n",
    "        left join propertylandusetype using(propertylandusetypeid)\n",
    "        left join storytype using(storytypeid)\n",
    "        left join typeconstructiontype using(typeconstructiontypeid)\n",
    "        where transactiondate between '2017-01-01' and '2017-12-31'\n",
    "        order by parcelid, transactiondate\n",
    "        \"\"\"\n",
    "\n",
    "zillow = acquire.get_zillow_data(query, '1')\n",
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32055, 35)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zillow = wrangle_zillow.wrangle_zillow_mvp(zillow)\n",
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
